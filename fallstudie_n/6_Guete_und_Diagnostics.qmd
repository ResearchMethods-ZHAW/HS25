---
execute:
  echo: true   # set to true to show musterlösung
  output: true # set to true to show musterlösung
code-fold: true
code-summary: "Musterlösung"
knitr:
  opts_chunk: 
    collapse: true
---

# Modellgüte und -diagnostics MM

## Libraries laden

Packages die wir für die Modelle und die Diagnostics brauchen

```{r}
#| echo: true
#| code-fold: false

library("lme4")
library("bbmle")
library("MuMIn")
library("dplyr")
library("readr")
library("ggplot2")
library("DHARMa")
library("car")
library("MASS")
library("ROCR")
library("sjPlot")
library("ggeffects")
library("sjstats")
library("cowplot")
library("gstat")
library("purrr")
library("broom.mixed")
```

## Ausgangslage

- Der Modellfit aus Aufgabe 5 von letzter Woche dient als Ausgangspunkt für die heutigen Übungen. 

```{r}
#| echo: true
#| code-fold: false

DF_mod_day <- read_delim("datasets/fallstudie_n/Aufgabe4_Datensatz_Habitatnutzung_Modelle_241028.csv", delim = ";") |>
  filter(time_of_day == "day") |>
  mutate(
    slope_scaled = scale(slope),
    topo_pos_scaled = scale(topo_pos),
    us_scaled = scale(us_2014),
    os_scaled = scale(os_2014),
    forest_prop_scaled = scale(forest_prop),
    dist_road_trails_scaled = scale(dist_road_trails),
    dist_road_only_scaled = scale(dist_road_only),
    dist_sett_scaled = scale(dist_sett),
    id = as.factor(id)
  )

f <- pres_abs ~
  slope_scaled +
  topo_pos_scaled +
  us_scaled +
  forest_prop_scaled +
  dist_road_only_scaled +
  dist_sett_scaled 

f <- paste(c(f, "+ (1 | id)"), collapse = " ") |> as.formula()

m_day <- glmer(f, data = DF_mod_day, family = binomial, na.action = "na.fail")

all_m <- dredge(m_day)
all_m

avgmodel <- model.avg(all_m, rank = "AICc", subset = delta < 2)
summary(avgmodel)
```

- Die Modellresultate aus dem avgmodel sind grundsätzlich die finalen Resultate die bereits interpretiert werden könnten. Allerdings funktionieren die Diagnosetests und die Darstellung der Resultate mit diesem gemittelten Modell nicht sehr gut, weshalb wir einen re-fit mit glmer machen müssen (an den Resultaten ändert sich dadurch nichts) 

```{r}
#| echo: true
#| code-fold: false

# hier zum Vergleich, dass die Resulate sich nur marginal verändern

summary(avgmodel)
summary(m_day)
```

## Aufgabe 1

Berechung der AUC (area under the receiver operating characteristic curve) **= Mass der Modellgüte**

Für die Berechnung des AUC findet ihr weiterführende Informationen unter: [Link](simtest.pdf) 

```{r}
#| echo: true
#| output: false
#| code-fold: false

prob <- predict(m_day, type = c("response"))
pred <- prediction(prob, DF_mod_day$pres_abs)

# AUC

auc <- performance(pred, measure = "auc")@y.values[[1]]
auc
```

## Aufgabe 2

Interpretieren der Modell-Residuen mittels Tests auf verschiedene Aspekte

- Model testing for over/underdispersion, zeroinflation and spatial autocorrelation following the DHARMa package.
- unbedingt die Vignette des DHARMa-Package konsultieren: [Link](https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html)

```{r}
#| eval: false
#| output: false
#| echo: true
#| code-fold: false

# Residuals werden über eine Simulation auf eine Standard-Skala transformiert und
# können anschliessend getestet werden. Dabei kann die Anzahl Simulationen eingestellt
# werden (dauert je nach dem sehr lange)

simulationOutput <- simulateResiduals(fittedModel = m_day, n = 10000)

# plotting and testing scaled residuals

plot(simulationOutput)
testResiduals(simulationOutput)

# The most common concern for GLMMs is overdispersion, underdispersion and
# zero-inflation.

# separate test for dispersion

testDispersion(simulationOutput)

# test for Zeroinflation

testZeroInflation(simulationOutput)

# test for spatial Autocorrelation

# calculating x, y positions per group
groupLocations <- aggregate(DF_mod_day[, 3:4], list(DF_mod_day$x, DF_mod_day$y), mean)
groupLocations$group <- paste(groupLocations$Group.1, groupLocations$Group.2)
groupLocations <- groupLocations |> dplyr::select(x,y,group)



# calculating residuals per group
res2 = recalculateResiduals(simulationOutput, group = groupLocations$group)

# running the spatial test on grouped residuals
testSpatialAutocorrelation(res2, groupLocations$x, groupLocations$y, plot = F)

# Testen auf Multicollinearität (dh zu starke Korrelationen im finalen Modell, zB falls
# auf Grund der ökologischen Plausibilität stark korrelierte Variablen im Modell)
# use VIF values: if values less then 5 is ok (sometimes > 10), if mean of VIF values
# not substantially greater than 1 (say 5), no need to worry.

car::vif(m_day)
mean(car::vif(m_day))
```

## Aufgabe 3

Graphische Darstellung der Modellresultate

```{r}
#| eval: false
#| output: false
#| echo: true
#| code-fold: false

# graphische Darstellung der gesamten Modellresultate

plot_model(m_day, transform = NULL, show.values = TRUE, value.offset = .3)

# Plotten der vorhergesagten Wahrscheinlichkeit, dass ein Kreis besetzt ist, in
# Abhängigkeit der erklärenden Variable basierend auf den Modellresultaten.

plot_model(m_day, type = "pred", terms = "us_scaled [all]")

# Problem: skalierte Variablen lassen sich nicht so ohne weiteres plotten, hier ein Hack um das Problem zu umgehen (Danke chatGPT!). 
# Die Einstellungen müssen für jede Variable separat geändert werden

# Plot erstellen
plot_obj <- plot_model(m_day, type = "pred", terms = "us_scaled [all]")

# Rücktransformation für die Achse: hier skalierten Werte anpassen

original_mean <- mean(DF_mod_day$us_2014)  
original_sd <- sd(DF_mod_day$us_2014)  

min_us <- min(DF_mod_day$us_2014)
max_us <- max(DF_mod_day$us_2014)


plot_obj +
  scale_x_continuous(
    limits = c((min_us - original_mean) / original_sd, (max_us - original_mean) / original_sd),  # skaliert
    breaks = seq((min_us - original_mean) / original_sd, (max_us - original_mean) / original_sd, length.out = 5),  # automatische Schritte
    labels = function(x) round(x * original_sd + original_mean, 2),  # Rücktransformierte Labels
    name = "Deckungsgrad Strauchschicht"
  )


# Funktion um viele Plots auf einem zusammenbringen: cowplot-package (hat auch sonst
# gute Funktionen für schöne Layouts für Grafiken)

cowplot::plot_grid()
```

## Aufgabe 4

Ermittlung des individuellen Beitrags der einzelnen Variablen im Gesamtmodell (leave-one-out Ansatz)

- Bestimmen delta AIC nach @coppes2017 → Vergleich des Gesamtmodells gegenüber einem Modell ohne die entsprechende Variable.
- Auftrag auf nächste Woche: Kurze Vorstellung der Modellresultate & Diagnostics im Plenum und Diskussion der Ergebnisse (keine PP-Präsentation nötig)

```{r}

vars <- c("slope_scaled", "forest_prop_scaled", "dist_road_only_scaled", "dist_sett_scaled", "topo_pos_scaled", "us_scaled")

# leave-one-out models
modelle <- lapply(vars, function(var) {
  formula <- as.formula(paste("pres_abs ~", paste(setdiff(vars, var), collapse = " + "), "+ (1 | id)"))
  glmer(formula, data = DF_mod_day, family = binomial, na.action = "na.fail")
})


names(modelle) <- paste0("m_", vars)

modelle <- c(list(m_day = m_day), modelle)


bbmle::AICtab(modelle)

```

## 

```{r}
#| eval: false
#| echo: false

# https://aosmith.rbind.io/2018/03/26/unstandardizing-coefficients/

coef_st = tidy(m_day, 
               effects = "fixed",
               conf.int = TRUE,
               conf.method = "profile")

coef_st

cbpp %>%
     select(y1:y3) %>%
     map(sd) %>% 
     stack()

sd_all = cbpp %>%
     select(y1:y3) %>%
     map(sd) %>%
     stack() %>%
     rename(sd = values) %>%
     mutate(ind = paste(ind, "s", sep = "_") )

sd_all

coef_st %>%
     inner_join(., sd_all, by = c("term" = "ind") )

coef_st %>%
     inner_join(., sd_all, by = c("term" = "ind") ) %>%
     mutate_at( .vars = vars(estimate, conf.low, conf.high), 
                .funs = list(~round( ./sd, 4) ) )

coef_unst = coef_st %>%
     inner_join(., sd_all, by = c("term" = "ind") ) %>%
     mutate_at( .vars = vars(estimate, conf.low, conf.high), 
                .funs = list(~round( ./sd, 4) ) ) %>%
     select(-effect, -(std.error:p.value), -sd)

coef_unst

round( fixef(fit1)[2:4], 4)

tidy(fit1, 
     effects = "fixed",
     conf.int = TRUE,
     conf.method = "profile")

```
